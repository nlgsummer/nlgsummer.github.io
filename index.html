<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <link rel="stylesheet" type="text/css" href="style.css">
  <title>Natural Language Generation Summer School</title>
    
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-59578456-1', 'auto');
  ga('send', 'pageview');

</script>
</head>

<body>

  <div id="main">
    <div>
      <img class="banner" src="images/Kin'sCollege.jpg"/>
    </div>


  <h1 id="header">Summer School on Natural Language Generation, Summarisation, and Dialogue Systems</h1>
  <h2>27th - 31st July 2015</h2>
  <p>
  The objective of this summer school is to introduce participants to the
  concepts and research questions in natural language generation (NLG),
  summarisation and dialogue systems. Although these three areas produce
  natural language, their distinct communities seldom interact because each
  community relies on different methods and because the inputs to each kind of
  system are different. There is, however, considerable overlap in the kinds of
  problems that need to be considered, from selecting the right content to
  evaluating the systems. We believe that focusing on the similarities of the
  different areas can stimulate "cross-pollination" of research. For example,
  most summarisation techniques could benefit from deeper semantic processing as
  performed in dialogue systems. Similarly, many NLG systems could benefit from
  techniques used by dialogue systems to substantially improve the generated
  output.
</p>
      
      <p>
          The summer school will be primarily aimed at PhD students and early career researchers but more experienced will be admitted to the extent that space permits. The registration will open at the end of February. The cost of registration will be £200 for students and £300 for others. 
      </p>

<h2>Summer School Time Table</h2>

<table>
  <tr>
    <th> Time</th>
    <th> Monday</th>
    <th> Tuesday</th>
    <th> Wednesday</th>
    <th> Thursday</th>
    <th> Friday</th>
  </tr>
  <tr>
    <td> 9:00-10:30</td>
    <td class="col"> Intro to NLG <br><span class="lec">Ehud Reiter</span></td>
    <td class="col"> Learning to Generate <br><span class="lec">Yannis Konstas</span></td>
    <td class="col"> Intro to Summarisation <br><span class="lec">Advaith Siddharthan</span></td>
    <td class="col"> System Evaluation <br><span class="lec">Ehud Reiter</span></td>
    <td class="col"> Readability <br><span class="lec">Thomas François</span></td>
  </tr>
  <tr>
      <td class="break">10:30-10:45</td>
      <td class="break">break</td>
      <td class="break">break</td>
      <td class="break">break</td>
      <td class="break">break</td>
      <td class="break">break</td>
  </tr>
  <tr>
    <td> 10:45-12:15</td>
    <td class="col"> NLG in Detail (Content Determination)<br><span class="lec">Chris Mellish</span></td>
    <td class="col"> Intro to Dialogue Systems <br><span class="lec">Paul Piwek</span></td>
    <td class="col"> Intro to Summarisation<br><span class="lec">Advaith Siddharthan</span></td>
    <td class="col"> Cognitive Modelling <br><span class="lec">Kees van Deemter</span></td>
    <td class="col"> Readability<br><span class="lec">Thomas François</span></td>
  </tr>
  <tr>
      <td class="break">12:15:13:00</td>
      <td class="break">lunch</td>
      <td class="break">lunch</td>
      <td class="break">lunch</td>
      <td class="break">lunch</td>
      <td class="break">lunch</td>
  </tr>
  <tr>
    <td> 13:00-14:30</td>
    <td class="col"> NLG in Detail (Micro Planning)<br><span class="lec">Albert Gatt</span></td>
    <td class="col">Intro to Dialogue Systems <br><span class="lec">Paul Piwek</span></td>
    <td class="col"> NLG in Practice<br><span class="lec">Yaji Sripada</span></td>
    <td class="col"> <br><span class="lec">(TBC)</span></td>
    <td class="col"> <br><span class="lec">(TBC)</span></td>
  </tr>
  <tr>
      <td class="break">14:30-14:45</td>
      <td class="break">break</td>
      <td class="break">break</td>
      <td class="break">break</td>
      <td class="break">break</td>
      <td class="break">break</td>
  </tr>
  <tr>
    <td> 14:45-16:15</td>
    <td class="col"> NLG in Detail (Surface Realisation)<br><span class="lec">Albert Gatt</span></td>
    <td class="col" rowspan="3">Open Lab <br><span class="lec">Yaji Sripada</span></td>
    <td class="col" rowspan="3">Open Lab <br><span class="lec">Yaji Sripada</span></td>
    <td class="col" rowspan="3">Open Lab <br><span class="lec">Yaji Sripada</span></td>
    <td class="col"> Discussion </td>
  </tr>
      <tr>
      <td class="break">16:15-16:30</td>
      <td class="break">break</td>
      <td class="end" rowspan="4">end</td>
    </tr>
    <tr>
      <td >16:30-18:00</td>
      <td class="col">Open Lab <br><span class="lec">Yaji Sripada</span></td>
    </tr>
    <tr>
      <td class="break">18:00-18:30</td>
      <td class="break" rowspan="2">Social Event</td>
      <td class="break">break</td>
      <td class="break">break</td>
      <td class="break">break</td>
    </tr>
    <tr>
        <td >18:30-19:30</td>
        <td class="col"> Evening Lecture<br><span class="lec">Paul Piwek</span></td>
        <td class="col"> Evening Lecture<br><span class="lec">Graham Ritchie</span></td>
        <td class="col"> Evening Lecture<br><span class="lec">(TBC)</span></td>
    </tr>
</table>

<h2>Course Summary</h2>
<ol>
    <li><span class="title">Introduction to NLG: </span> <span class="lec">Ehud Reiter (University of Aberdeen)</span><br>
        The basic concepts of NLG will be introduced, including document planning, microplanning,           and realisation.  Also examples of real NLG systems will be presented, including both what           they do and how they work.</li>
    <li>
    <span class="title"> NLG in detail </span><ul>
         <li><span class="title">Content Determination: </span><span class="lec">Chris Mellish (University of Aberdeen)</span></li>
        This talk will summarise existing approaches to content determination for NLG, as well as touching on the closely related topics of text ordering and structuring.  It will discuss why content determination is hard and what sorts of (hand-crafted or learned) models can be used to inform it. It is often useful to regard content determination as a search problem, and we will take this approach in order to compare the different methods that have been used.
         <li><span class="title">Micro-planning:</span><span class="lec">Albert Gatt (University of Malta)</span><br>

This session will be devoted to discussing different micro-planning tasks. In particular, we will review some of the “classic” sub-tasks that microplanners have often been designed to perform, notably:

(a) lexicalisation, the task of choosing the right words or lemmas to express the contents of the message;
(b) aggregation, the task of merging distinct representations into a single, more concise representation;
(c) referring expression generation, the task of selecting the content (and, to some extent, the form) of referential noun phrases in text.

Following a brief discussion of these “classic” sub-tasks, the session will then move on to a relatively under-studied problem in microplanning, which arises when the text being generated has “narrative” qualities — that is, it recounts events which, in addition to being related to each other in the generated discourse, are also related to each other in time. In this case, new questions arise in relation to choices the microplanner has to make, notably where tense, aspect and temporal connectives are concerned.

For the purposes of illustration, the discussion of these microplanning sub-tasks will be conducted  with reference to a concrete family of NLG systems, developed in the BabyTalk Project (Portet et al, 2009; Gatt et al, 2009; Hunter et al, 2011, 2012). However, reference will also be made to recent statistical approaches to NLG, in particular, the use of machine-learning methods to learn models from data that provide the kernel to the solutions of these sub-tasks.
             </li>
         <li><span class="title">Surface Realisation:</span><span class="lec">Albert Gatt (University of Malta)</span><br>
        In this session, we will first discuss the domain of realisation with reference to a number of different languages. The purpose of this is mainly to delineate the problem: different languages will make different demands on a realiser, and in some cases, syntactic choices will have repercussions for microplanning decisions.

Next, we will look at an overview of different realisers, starting with some classic rule-based examples, such as RealPro and KPML (Bateman, 1997). These will be contrasted with recent approaches, such as HALOGEN (Langkilde-Geary and Knight, 2002) or OpenCCG (White et al, 2007), where the aim is to minimise the rule-based component while allowing syntactic choices to be made probabilistically, usually through the use of n-gram based language models. In each of these cases — whether rule-based or statistical — there are assumptions made about the nature of the input, usually motivated by some theory of syntax.

Finally, we will distinguish realisers such as the above from “realisation engines”, which simply provide the tools to perform morphosyntactic realisation in a given language, without any commitment as to the nature of the input representation. As a specific case study, we will use SimpleNLG (Gatt and Reiter, 2009).
        
        
        </li>
        
        </ul>
    </li>
    <li><span class="title">Introduction to Summarisation:</span><span class="lec">Advaith Siddharthan (University of Aberdeen)</span><br>
        This tutorial will cover a range of text summarisation approaches described in the literature for extractive and abstractive summarisation, including models for sentence selection in extractive summarisation based on various statistical definitions of "topic", abstractive summarisation through aggregation and deletion, attempts at microplanning (e.g., generating referring expressions), the use of template based generation, and issues of text planning or sentence ordering. 

    </li>
    <li><span class="title">Introduction to Dialogue Systems: </span><span class="lec">Paul Piwek (Open University)</span><br>
The module will start with a question: What is dialogue? We will survey studies on human-human dialogue in search for a tentative answer. We then compare and contrast human-human dialogue with human-machine dialogue. This will lead us to an examination of various dialogue systems - past and present. We will consider dialogue system architectures and approaches to dialogue management. The module concludes with a look at recent developments, from incremental processing in dialogue to models of non-cooperative dialogue.
    </li>
    <li> <span class="title">Learning to generate: Concept-to-text generation using machine learning </span><span class="lec">Yannis Konstas (University of Edinburgh)</span><br>
        The explosion of the world wide web in the recent years has generated data that are both in very large amounts, as well is in obscure or inaccessible formats to
non-expert users (e.g., numeric, tabular forms, graphs, etc).
Several successful generation systems have been produced in the past twenty years, that mostly rely on human-crafted rules or expert-driven grammars.
While reliable and capable of generating high-quality output, such systems are usually difficult to exploit patterns in very large sets of data, as well as 
port to different domains, without significant human intervention.
In this tutorial, we will explore systems in NLG that learn the well-known pipeline modules of content selection, microplanning and surface realisation,
automatically from data. We will visit methods that model each step into a probabilistic model or other weighted function, and learn their parameters by optimising
a text output-related objective metric (e.g., BLEU, METEOR scores). Generation is then viewed as a common search problem, which entails finding the best 
combination of parameters given the trained model and an input. We will also compare systems that optimise each module in isolation, as well as jointly.
    </li>
    <li> <span class="title">Evaluation: </span><span class="lec">Ehud Reiter (University of Aberdeen)</span><br>
         Different ways to evaluate NLG systems will be discussed, including task-based, human-              based, and metric-based; what can we learn from these different types of evaluation?  We            will also summarise practice in each of these types of evaluations, and present the design          and outcomes of several real NLG evaluations.

    </li>
    <li> <span class="title">Cognitive Modelling:  the case of reference </span><span class="lec">Kees van Deemter (University of Aberdeen)</span><br>
        This lecture will discuss the idea that NLG systems can be seen as computational models of human language production, focussing on the production of referring expressions as a case study on which a substantial amount of work in recent years has focussed. I will discuss different types of computational models, and the different goals that these models can have, such as (1) emulating an average speaker in a corpus, (2) explaining the way in which speakers differ across a corpus, and (3) generating language that is easy to understand by human readers or hearers (e.g. in practical applications). These computational models will be compared with more traditional models developed in mainstream psycholinguistics.
    </li>
    <li> <span class="title">Readability:</span>
    </li>
</ol>
      
      <h2>Open Lab</h2>

    <h3><span class="lec">Yaji Sripada (University of Aberdeen)</span></h3>
       <p> The Open Lab sessions are your opportunity to test your learning at the summer school. You will build an NLG system end-to-end using the software modules we provide. You can work alone or as a team. The idea is not to push you into writing code round-the-clock to build loads of functionality. Instead you will be encouraged to focus on learning first-hand the design choices and trade-offs involved in building an NLG application. If you are new to computer programming but willing to learn, help will be available in these supervised lab sessions to get you started with your first program!
</p>
      
      
      <h2>Evening lectures</h2>
        <ul>
        <li><span class="title"> Graeme Ritchie (University of Aberdeen)</span>  <span class="lec">Creative Language Generation</span> <br>
        Over the past two decades, the field of computational creativity has come into being, and grown considerably. Its aim is "to model, simulate or replicate creativity using a computer". To this end, most of the work focusses on building software which engages in activities commonly thought, within society, to be creative, such as visual art, concept generation, musical composition, etc. Many of these domains involve natural language (e.g. poetry, stories, jokes), and hence such work can be seen as a subarea, creative language generation. This talk will give a general introduction to the field of computational creativity, briefly review some of the language-based work, and discuss some of the methodological issues raised by such research.
    
        </li>
        <li>
            <span class="title"> Paul Piwek (Open University)</span>  <span class="lec">TBC</span> <br>
        </li>
        </ul>
      
    <h2>Sponsors </h2>  
      <div id="sponsor">
        <img src="images/SICSA%20logo.png" class="logo"/>
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        <img src="images/Aberdeen_Uni_logo.jpg" class="logo"/>
      </div>

 <br>
<hr>
    <footer>
    <p>Send us an <a href="mailto:nlg.summer@abdn.ac.uk">email</a>  if you have a question.</p>
      <p>Last update: 17th February 2015</p>
    </footer>

 </div>
</body>
</html>
